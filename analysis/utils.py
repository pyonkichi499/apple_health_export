#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ±ç”¨ãƒ˜ãƒ«ã‚¹ãƒ‡ãƒ¼ã‚¿åˆ†æã‚·ã‚¹ãƒ†ãƒ  - å…±é€šãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
æ—¥ä»˜è§£æã€ãƒ•ã‚©ãƒ³ãƒˆè¨­å®šã€çµ±è¨ˆè¨ˆç®—ãªã©ã®å…±é€šæ©Ÿèƒ½
"""

import csv
import os
from datetime import datetime, date
from collections import defaultdict
import statistics
import matplotlib
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm

def setup_japanese_font():
    """åˆ©ç”¨å¯èƒ½ãªæ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆã‚’è‡ªå‹•æ¤œå‡ºã—ã¦è¨­å®š"""
    # å€™è£œãƒ•ã‚©ãƒ³ãƒˆãƒªã‚¹ãƒˆï¼ˆå„ªå…ˆé †ä½é †ï¼‰
    japanese_fonts = [
        'Hiragino Kaku Gothic ProN',
        'Hiragino Sans GB',
        'Arial Unicode MS',
        'AppleGothic',
        'PingFang SC',
        'DejaVu Sans'
    ]

    # ã‚·ã‚¹ãƒ†ãƒ ã§åˆ©ç”¨å¯èƒ½ãªãƒ•ã‚©ãƒ³ãƒˆä¸€è¦§ã‚’å–å¾—
    available_fonts = [f.name for f in fm.fontManager.ttflist]

    # åˆ©ç”¨å¯èƒ½ãªæ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆã‚’æ¤œç´¢
    for font in japanese_fonts:
        if font in available_fonts:
            print(f"âœ… æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆä½¿ç”¨: {font}")
            plt.rcParams['font.family'] = font
            return font

    # æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆ
    print("âš ï¸ æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ•ã‚©ãƒ³ãƒˆã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
    plt.rcParams['font.family'] = 'DejaVu Sans'
    return 'DejaVu Sans'

def parse_date(date_str):
    """æ—¥æ™‚æ–‡å­—åˆ—ã‚’datetimeã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã«å¤‰æ›"""
    try:
        return datetime.strptime(date_str.split(' +')[0], '%Y-%m-%d %H:%M:%S')
    except:
        try:
            return datetime.strptime(date_str.split(' +')[0], '%Y-%m-%d')
        except:
            return None

def load_csv_data(file_path, start_date=None, end_date=None):
    """CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã€æ—¥ä»˜ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã‚’é©ç”¨"""
    data = []

    if not os.path.exists(file_path):
        print(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {file_path}")
        return data

    try:
        with open(file_path, 'r', encoding='utf-8') as file:
            reader = csv.DictReader(file)
            for row in reader:
                date_obj = parse_date(row['startDate'])

                if not date_obj:
                    continue

                # æ—¥ä»˜ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
                if start_date and date_obj.date() < start_date:
                    continue
                if end_date and date_obj.date() > end_date:
                    continue

                data.append({
                    'date': date_obj,
                    'value': row.get('value', ''),
                    'source': row.get('sourceName', ''),
                    'raw_data': row
                })

    except Exception as e:
        print(f"âŒ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")

    return data

def calculate_basic_statistics(values):
    """åŸºæœ¬çµ±è¨ˆé‡ã‚’è¨ˆç®—"""
    if not values:
        return {}

    return {
        'count': len(values),
        'mean': statistics.mean(values),
        'median': statistics.median(values),
        'min': min(values),
        'max': max(values),
        'std': statistics.stdev(values) if len(values) > 1 else 0,
        'range': max(values) - min(values)
    }

def aggregate_daily_data(data, aggregation='mean', value_column='value'):
    """ãƒ‡ãƒ¼ã‚¿ã‚’æ—¥åˆ¥ã«é›†ç´„"""
    daily_data = defaultdict(list)

    for entry in data:
        try:
            value = float(entry[value_column])
            date_key = entry['date'].date()
            daily_data[date_key].append(value)
        except (ValueError, KeyError):
            continue

    daily_results = []

    for date_key in sorted(daily_data.keys()):
        values = daily_data[date_key]

        if aggregation == 'mean':
            agg_value = statistics.mean(values)
        elif aggregation == 'sum':
            agg_value = sum(values)
        elif aggregation == 'max':
            agg_value = max(values)
        elif aggregation == 'min':
            agg_value = min(values)
        else:
            agg_value = statistics.mean(values)  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ

        daily_results.append({
            'date': datetime.combine(date_key, datetime.min.time()),
            'value': agg_value,
            'count': len(values)
        })

    return daily_results

def calculate_rolling_average(daily_data, window_days=7):
    """ç§»å‹•å¹³å‡ã‚’è¨ˆç®—"""
    if len(daily_data) < 3:
        return []

    rolling_data = []

    for i in range(len(daily_data)):
        # ç¾åœ¨ã®æ—¥ä»˜ã‚’ä¸­å¿ƒã«å‰å¾Œã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        start_idx = max(0, i - window_days // 2)
        end_idx = min(len(daily_data), i + window_days // 2 + 1)

        # ç§»å‹•å¹³å‡è¨ˆç®—
        window_values = [daily_data[j]['value'] for j in range(start_idx, end_idx)]

        if len(window_values) >= 3:  # æœ€ä½3æ—¥åˆ†ã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆã®ã¿
            rolling_avg = statistics.mean(window_values)
            rolling_data.append({
                'date': daily_data[i]['date'],
                'value': rolling_avg
            })

    return rolling_data

def split_data_by_gaps(daily_data, gap_days=30):
    """ãƒ‡ãƒ¼ã‚¿æ¬ ææœŸé–“ã§ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†å‰²"""
    if len(daily_data) <= 1:
        return [daily_data]

    segments = []
    current_segment = [daily_data[0]]

    for i in range(1, len(daily_data)):
        prev_date = daily_data[i-1]['date']
        curr_date = daily_data[i]['date']

        # æ—¥ä»˜é–“ã®é–“éš”ã‚’è¨ˆç®—
        gap = (curr_date - prev_date).days

        if gap > gap_days:
            # æŒ‡å®šæ—¥æ•°ä»¥ä¸Šã®é–“éš”ãŒã‚ã‚‹å ´åˆã€ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’åˆ†å‰²
            if len(current_segment) > 1:  # 1ç‚¹ã ã‘ã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã¯é™¤å¤–
                segments.append(current_segment)
            current_segment = [daily_data[i]]
            print(f"ğŸ“Š ãƒ‡ãƒ¼ã‚¿åˆ†å‰²: {prev_date.strftime('%Y-%m-%d')} â†’ {curr_date.strftime('%Y-%m-%d')} ({gap}æ—¥é–“ã®æ¬ æ)")
        else:
            current_segment.append(daily_data[i])

    # æœ€å¾Œã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’è¿½åŠ 
    if len(current_segment) > 1:
        segments.append(current_segment)

    return segments

def format_number(value, unit='', decimal_places=1, show_sign=False):
    """æ•°å€¤ã‚’é©åˆ‡ãªå½¢å¼ã§ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
    # ç¬¦å·ã®å‡¦ç†
    if show_sign and value >= 0:
        sign = '+'
    else:
        sign = ''

    if unit in ['kg', '%']:
        return f"{sign}{value:.{decimal_places}f} {unit}"
    elif unit in ['kcal', 'æ­©', 'count']:
        return f"{sign}{value:.0f} {unit}"
    else:
        return f"{sign}{value:.{decimal_places}f} {unit}"

def ensure_data_directory():
    """ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã™ã‚‹ã“ã¨ã‚’ç¢ºèª"""
    base_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
    data_dir = os.path.join(base_dir, 'data', 'csv')

    if not os.path.exists(data_dir):
        print(f"âŒ ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {data_dir}")
        return None

    return data_dir

# ãƒ•ã‚©ãƒ³ãƒˆè¨­å®šã‚’è‡ªå‹•å®Ÿè¡Œ
setup_japanese_font()
